% !TEX root = ../Chapter5.tex
\section{General Parallel Optimization}\label{sec:gpo.gpo}

We present our new wrapper in this section. In order to get a better understanding, we start with a brief introduction of \gls{poo}.

\subsection{Generic parallel optimistic optimization}\label{sec:gpo.gpo.generic}

We introduce $\gls{poo}(\cA)$ as a generic  algorithm, taking as input \emph{any} hierarchical optimization algorithm $\cA=\cA(\nu,\rho)$ requiring the smoothness parameters.

$\gls{poo}(\cA)$ is a meta-algorithm that uses $\cA$ that knows the smoothness as a subroutine, originally proposed by~\cite{grill2015poo} for $\cA = \gls{hoo}$. In this algorithm, several instances of $\cA$ are run in parallel, each one using a different pair of parameters $(\nu,\rho)$ in a well-chosen grid~$\cG$ (defined in Line~4 of Algorithm~\ref{alg:pct}). In the end, $\gls{poo}(\cA)$ chooses the instance that has the largest empirical mean reward and returns one of the points evaluated by this instance, chosen uniformly at random.

The pseudo-code of $\POO(\cA)$ is shown in Algorithm~\ref{alg:pct}. Additionally to the base algorithm itself, it requires two parameters $\rho_{\max}$ and $\nu_{\max}$ that determine the range of instances $\cA(\nu,\rho)$ that we can compete with. However, these parameters can be set as a function of the number of evaluations as explained in details in Appendix C of~\cite{grill2015poo}, hence not mandatory in practice. An important remark is that given a budget $N$ of function evaluations, the number of instances $M$ run by $\gls{poo}(\cA)$ depends on $N$, and each instance is run for $\floor{N/M(N)}$ times. Due to the doubling scheme used in Lines~2-10 of Algorithm~\ref{alg:gpo}, note however that $\gls{poo}(\cA)$ does not need to know this total number of function evaluations. Hence, if the base algorithm $\cA$ is anytime, so is $\gls{poo}(\cA)$.

\begin{algorithm}[ht]
\centering
\caption{Algorithm of $\POO(\cA)$ with base algorithm $\cA$}
\label{alg:pct}
\begin{algorithmic}[1]
    \State {\bfseries Input:} base algorithm $\cA$, $\nu_{\max}$,$\rho_{\max}$, branching factor of the partitioning $K$
    \State {\bfseries Initialization:} $D_{\max} \gets \ln K/\ln\left( 1/\rho_{\max}\right)$, number of function evaluations $n \gets 0$, current number of instances of $\cA$: $N \gets 1$, $\mathcal{S} \gets \{(\nu_{\max},\rho_{\max})\}$
    
    \While{budget still available}
        \While{$N \le \tfrac{1}{2}D_{\max}\log\left(N/(\log N)\right)$}
            \For{$i\gets1, \dots, N$}
        		\State $s \gets \left(\nu_{\max},{\rho_{\max}}^{2M/(2i+1)}\right)$
        		\State \text{Initialize} $\cA(s)$ (if not already done before) 
        		\State \text{Continue running} $\cA(s)$ \text{until it has given} $\frac{N}{M}$ \text{rewards} $r_{s,1},\ldots,r_{s,N/M}$.
        		\State \text{Compute} $\widehat{\mu}[s] = \frac{M}{N}\sum_{i=1}^{N/M}r_{s,i}.$
        	\EndFor
            \State $N \gets 2N$
            \State $M \gets 2M$
        \EndWhile
        \State \text{Perform each $\cA(s)$ once} 
        \State \text{Update} $\widehat{\mu}[s]$
        \State $N \gets N+M$
    \EndWhile
    \State $s^\star \gets \argmax_{s\in\mathcal{S}}~\widehat{\mu}[s]$
    \State {\bfseries Return} A point sampled u.a.r.\,from the points evaluated by $\cA(s^\star)$
\end{algorithmic}
\end{algorithm}

\subsection{A more general wrapper}\label{sec:gpo.gpo.gpo}

The analysis of $\gls{poo}(\cA)$ heavily relies on the fact that we control the \emph{cumulative regret} of algorithm $\cA$ (see Appendix~\ref{app:gpo.hct} for details). $\gls{poo}$ indeed exploits this property when selecting $s^\star$ as the instance with largest empirical cumulative rewards. In this section, we propose a simple modification of $\gls{poo}(\cA)$ that allows using as base algorithms any hierarchical optimization algorithms that would only have \emph{simple regret} guarantees. 

The $\gls{gpo}(\cA)$ algorithm, whose pseudo-code is shown in Algorithm~\ref{alg:gpo},  mostly needs to modify the model selection strategy of \gls{poo}. There are two natural candidates: (i) Lepski's method which is a nested aggregation scheme~\citep{lepski1992,lepski1997,locatelli2017adaptivity,locatelli2018adaptivity} that requires a single optimum, thus not directly applicable to our case, and (ii) a cross-validation scheme that we use and detail in the next. Given a total budget of $n$ function evaluations, $\gls{gpo}(\cA)$ runs several instances of $\cA$ in parallel with parameters chosen in the same grid as that used by \gls{poo}, each using the same number of evaluations to output a recommendation $\tilde{x}_i$. One half of the budget is then dedicated to estimating the function values at those points, and the one with the highest estimated value is kept. 

\begin{algorithm}[ht]
\centering
\caption{Algorithm of \GPO{}}
\label{alg:gpo}
\begin{algorithmic}[1]
    \State {\bfseries Input:} base algorithm $\cA$, budget $n$, $\rho_{\max}, \nu_{\max}$, $K$
    \State {\bfseries Initialization:} $D_{\max} \gets \ln K/\ln\left( 1/\rho_{\max}\right)$, number of function evaluations $N \gets 0$, current number of instances of $\cA$ $M \gets 1$, $\mathcal{S} \gets \{(\nu_{\max},\rho_{\max})\}$

    \State \text{Compute} $M = \lceil (1/2)D_{\max}\ln((M/2)/\ln(M/2))\rceil$ (the number of instances)
    \For{$i\gets 1, \dots, M$}
    	\State $s \gets \left(\nu_{\max},{\rho_{\max}}^{2M/(2i+1)}\right)$
		\State \text{Run} $\cA(s)$ \text{for} $\lfloor N/(2M)\rfloor$ \text{time steps}
		\State \text{Recommend} $\tilde x_s$
		\State \text{Get} $\lfloor N/(2M)\rfloor$ \text{noisy evaluations of} $f(\tilde{x}_s)$
		\State \text{Compute their average} $V[s]$
	\EndFor
% \For{$j \gets 1, \dots, N$}{
% 	$\tilde{x_{j}} \gets$ A point sampled u.a.r.\,from the points evaluated by \HCT{}($\nu_{\max},\rho_j$)\\
% 	Evaluate $\tilde{x_{j}}$ by $N^+$ times\\
% 	$\hat{\mu}_{N^+,j} \gets \frac{1}{N^+} \sum_{i=1}^{N^+} r_{i,j}$, where $r_{i,j}$ are i.i.d observations of $f(\tilde{x}_j)$\\
% 	}
    \State ${s^\star} \gets \argmax_{s} V[s]$
    \State {\bfseries Return} $\tilde x_{s^\star}$
\end{algorithmic}
\end{algorithm}

In Theorem~\ref{thm:gpo.gpo}, we provide a general analysis of the \gls{gpo} algorithm, showing that it attains an (order)-optimal simple regret without knowing the parameter triple $(\nu^\star,C^\star,\rho^\star)$ provided that its base algorithm does.

\begin{theorem}\label{thm:gpo.gpo}
\begin{leftbar}[theorembar]
If for all $(\nu,\rho)$ the $\cA(\nu,\rho)$ algorithm has its \emph{simple regret} bounded as
\begin{equation}\label{crucialHypothesis}
    \mathbb{E}\left[S_N^{\cA(\nu,\rho)}\right] \leq \alpha C\left(\left(\log N /N\right)^{1/(d(\nu,C,\rho)+2)}\right),
\end{equation}
for any function $f$ satisfying Assumption~\ref{ass:gpo.local} with parameters $(\nu,\rho)$, then there exists a constant $\beta$ that is independent of $\nu_{\max}$ and $\rho_{\max}$ such that 
\[
    \mathbb{E}\left[S_N^{\gls{gpo}(\cA)}\right]  \leq \beta D_{\max}(\nu_{\max}/\nu^\star)^{D_{\max}} \left( (\log^2 N)/N)^{1/(d(\nu^\star,C^\star,\rho^\star)+2)} \right)\,,
\]
for any function $f$ satisfying Assumption~\ref{ass:gpo.local} with parameters $\nu^\star \leq \nu_{\max}$ and $\rho^\star\leq \rho_{\max}$.
\end{leftbar}
\end{theorem}

\begin{proof} 
We start by fixing some notation. Recall that $M$ (that depends on $N$) is the number of instances run in parallel. For $j \in \{1,\dots,M\},$ we let $\tilde{x}_j$ denote the point recommended by the instance $\cA(\nu_{\max},\rho_{j})$ with $\rho_j = \rho_{\max}^{2M/(2j+1)}$. Let $(r_{i,j})_{1 \leq i \leq N^+}$ be the i.i.d.\,evaluations of $f(\tilde{x}_j)$ used during the validation phase, with $N^+ \triangleq \lfloor N/(2M)\rfloor$ and $\hat{\mu}_{N^+,j} = \frac{1}{N^+}\sum_{i=1}^{N^+} r_{i,j}$ be the estimated value of $f(\tilde{x}_j)$ computed by the algorithm. We let \[\hat{\jmath} = \argmax_j \ \hat{\mu}_{N^+,j} \ \ \text{and} \ \ \ \tilde{\jmath} = \argmax_j \ f(\tilde{x}_j)\] 
be the index of the empirical best and true best among the recommended point. 
We notice that for any $j$, $\{r_{i,j}-f(\tilde{x}_{j})\}_{i=1}^{N^+}$ is a bounded i.i.d.\,sequence with zero mean (conditionally to $\tilde{x}_j$) thus using Hoeffding's inequality one can show that for all $\Delta > 0$,
\[
    \PP{\sum_{i=1}^{N^+}(r_{i,j}-f(\tilde{x_{j}})) > N^+\Delta} \leq \exp{\left(-2N^+\Delta^2\right)},
\]
therefore,
\[
    \PP{\hat{\mu}_{N^+,j}-f(\tilde{x_{j}}) > \Delta} \leq \exp{\left(-2N^+\Delta^2\right)},
\]
and we have immediately
\[
    \PP{\abs{\hat{\mu}_{N^+,j}-f(\tilde x_{j})} > \Delta} \leq 2\exp{\left(-2N^+\Delta^2\right)}.
\]
By integrating over $\Delta\in [0,1]$, we get
\begin{equation}\label{eq:azuma}
    \forall j\in \{1,\dots,M\}, \ \EE{\abs{\hat{\mu}_{N^+,j}-f(\tilde{x}_{j})}} \leq \frac{\sqrt{\pi/2}}{\sqrt{N^+}}\cdot
\end{equation}
As in the analysis of $\gls{poo}$, the instance $\overline{\jmath}$ defined as   
\[
	\bar{\jmath} \eqdef \underset{j \leq M : \rho_j\geq\rho^\star}{\argmin} \left[d(\nu_{\max},C^\star,\rho_j) - d(\nu^\star,C^\star,\rho^\star)\right]
\]
shall play a crucial role. Indeed, inequality \eqref{crucialHypothesis} is exactly what is needed in Appendix B.2 and Appendix B.3 of~\cite{grill2015poo} to control the simple regret of that instance in terms of $(\nu^\star,C^\star,\rho^\star)$. Following the exact same steps, we can show that for some constant $\alpha$, 
\begin{equation}\label{eq:regretjbar}
    \mathbb{E}\left[S_{(N/2M)}^{\cA(\nu_{\max},\rho_{\overline{\jmath}})}\right]  \leq \alpha D_{\max}(\nu_{\max}/\nu^\star)^{D_{\max}} \left( (\log^2 N)/N)^{1/(d(\nu^\star, C^\star,\rho^\star)+2)} \right)\,.
\end{equation} 
We now turn our attention to the simple regret of $\gls{gpo}{}(\cA)$ after $n$ function evaluations.
\begin{equation}\label{eq:cv}
    \EE{S_N^{\gls{gpo}}} = \EE{f^\star - f(\tilde{x}_{\hat\jmath})} = \EE{f^\star - f(\tilde{x}_{\bar{\jmath}})} + \EE{f(\tilde{x}_{\bar{\jmath}}) - f(\tilde{x}_{\tilde{\jmath}})} + \EE{f(\tilde{x}_{\tilde{\jmath}}) - f(\tilde{x}_{\hat{\jmath}})}\,.
\end{equation}
The first term in~\eqref{eq:cv} is equal to the simple regret of the instance $\overline{\jmath}$ that uses $n/N$ samples, which is upper bounded in \eqref{eq:regretjbar}. The second term in~\eqref{eq:cv} is always negative by definition of~$\tilde{\jmath}$ and the third term can be rewritten as
\begin{equation}\label{AstuteDec}
    \EE{f(\tilde{x}_{\tilde{\jmath}}) - f(\tilde{x}_{\hat{\jmath}})} = \EE{f(\tilde{x}_{\tilde{\jmath}}) - \hat{\mu}_{N^+,\tilde{\jmath}}} + \EE{\hat{\mu}_{N^+,\tilde{\jmath}} - \hat{\mu}_{N^+,\hat{\jmath}}} + \EE{\hat{\mu}_{N^+,\hat{\jmath}} - f(\tilde{x}_{\hat{\jmath}})}\,.
\end{equation}
where the first and the third term of~\eqref{AstuteDec} are both upper bounded by $(\sqrt{\pi/2})/\sqrt{N^+}$ using \eqref{eq:azuma}, and the second term is always negative by definition of $\hat{\jmath}$.
Putting things together yields 
\[    
    \EE{S_N^{\gls{gpo}}}  \leq \alpha D_{\max}(\nu_{\max}/\nu^\star)^{D_{\max}} \left( (\log^2 N)/N\right)^{1/(d(\nu^\star, C^\star,\rho^\star)+2)}+ O\left(\frac{\sqrt{M}}{\sqrt{N}}\right)\,.
\]

The conclusion follows by observing that the second term in the right-hand side is negligible with respect to the first. 
\end{proof}
