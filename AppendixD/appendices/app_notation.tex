\section{Notation}\label{app:gpo.notation}

\begin{table}[ht]
	\centering
	\caption{Table of notation for Chapter~\ref{CHAP:GPO}.}
	\begin{tabular}{@{}l|l@{}}
		\toprule
		\thead{Notation} & \thead{Meaning} \\ \midrule
		$c_1 \triangleq (\rho/(3\nu))^{1/8}$ & constant \\
        $c \triangleq 2\sqrt{1/(1-\rho)}$ & constant \\
		$\mathcal{I}_h(n)$ & set of nodes created by \gls{hct} at level $h$ up to step $n$ \\
        $\mathcal{I}_h^{+}(n)$ & subset of $\mathcal{I}_h(n)$ which contains only the internal nodes \\
        $(h_n,i_n)$ & node selected by the algorithm at each step $n$ \\
        $\mathcal{C}_{h,i} \triangleq \{n = 1,\cdots,N : (h_n,i_n) = (h,i)\}$ & all the time that $(h,i)$ is selected by the algorithm \\
        $\mathcal{C}_{h,i}^{+} \triangleq \underset{j\in\{0,\ldots,K-1\}}{\bigcup} \cC_{h+1,Ki-j}$ & set of child nodes of $(h_n,i_n)$ \\
        $\overline{n}_{h,i} \triangleq \max_{n\in\mathcal{C}_{h,i}} n$ & last time $(h,i)$ has been selected \\
        $\tilde{n}_{h,i} \triangleq \max_{n\in\mathcal{C}_{h,i}^{+}} n$ & last time when one of its children has been selected \\
        $n_{h,i} \triangleq \min\{n: T_{h,i}(N) \geq \tau_h(n)\}$  & time when $(h,i)$ is expanded \\
        $\hbx_n$ & arm pulled at time $n$ \\
        $T_n^\bx = \sum_{t=1}^n \ind_{\{\hbx_t = \bx\}}$ & number of draws of arm $\bx$ at time $n$\\
        $\bT_n =(T_n^\bx)_{\bx\in\cX}$ & vector of number of draws\\
        $T_n^{\bx,i} = \sum_{t=1}^n \ind_{\{\hbx_t = \bx, i_t = i\}}$ & number of draws of arm $\bx$ for a given answer $i$\\
        $\lambda$ & regularization parameter\\
        $\hbtheta_n^\lambda$ & regularized least square estimate\\
		\bottomrule
	\end{tabular}
\end{table}

We further introduce some additional notation that are needed for the proof of Theorem~\ref{thm:gpo.hct}.
\begin{itemize}
    \item For any $t$, let $y_n\triangleq(r_n,x_n)$ be a random variable, we define the filtration $\cF_n$ as a $\sigma$-algebra generated by $(y_1,\ldots,y_n)$.
    \item Another important notion in \gls{hct} is the threshold $\tau_h$ on the number of pulls needed before a node at level $h$ can be expanded. The threshold $\tau_h$ is chosen such that the two confidence terms in $U_{h,i}$ are roughly equivalent, that is,
    \[
        \nu\rho^h \simeq c\sqrt{\frac{\log(1/\tilde{\delta}(n^+))}{\tau_h(n)}}\,.
    \]
    Therefore, we choose
    \[
        \tau_h(n) \triangleq \ceil{\frac{c^2\log(1/\tilde{\delta}(n^+))}{\nu^2}\rho^{-2h}}\,.
    \]
    Since $n^+$ is defined as $2^{\ceil{\log(n)}}$, we have $n \leq n^+ \leq 2n$. In addition, $\log$ is an increasing function, thus we have
    \begin{equation}\label{eq:gpo.pre}
        \frac{c^2}{\nu^2}\rho^{-2h} \leq \frac{c^2 \log(1/\tilde{\delta}(n))}{\nu^2}\rho^{-2h} \leq \tau_h(n) \leq \frac{c^2\log(2/\tilde{\delta}(n))}{\nu^2}\rho^{-2h},
    \end{equation}
    where the first inequality follows from the fact that $0<\tilde{\delta}(n)\leq1/2$. 
\end{itemize}
